---
title: "My First Notebook MDA2024"
output: html_notebook
---

# Introduction


# 1. Data Description

## 1.1. Sample Selected

You can define bullet list or numbered list:

- Pizza
- Pasta
- Cafe
  - Espresso
  - Macchiato
  - Cappuccino
- Vodka
  - Bisont Grass
  - Soplica

## 1.2. Formula

Here you can define formula

$$ y = \beta_0 + \beta_1X + \epsilon $$
the formula can be reported in the text: $\mu = 1/n \sum X_i$

## 1.3. Import Data (CSV) [*]

- Pre-trained Models:
  - https://www.kaggle.com/models

- Open psychology data [raw data]:
  - http://openpsychometrics.org/_rawdata/

- Info about used data [DS-3]:
  - openpsychometrics.org/tests/SD3/
    - Dark Triad Personality Test [data]
    - SD-3 stands for Short Dark Triad

```{r}
data_SD3 <- read.delim("~/RProjects/2024-Q2-R-2 [MDA2024, exercises]/D1_SD3/data_SD3.csv", stringsAsFactors=TRUE)
```

## [ 1.3. BONUS ]

- Imported:
  - Forbes2000.csv
  - glass.csv

```{r}
Forbes2000 <- read.csv("~/RProjects/2024-Q2-R-2 [MDA2024, exercises]/D0_Data/Forbes2000.csv", stringsAsFactors=TRUE)
```

```{r}
glass <- read.csv("~/RProjects/2024-Q2-R-2 [MDA2024, exercises]/D0_Data/glass.csv", stringsAsFactors=TRUE)
```

# 2. Data Analysis
To add R code in the Notebook we need to use the **Chunk**.

```{r}
X <- iris
```

It is possible to have an overview of the data by using the *summary* function.

```{r}
summary(X)
```
In R there are three main type of data:

- **Matrix**. Mathematical Object. In our example **Y** is a matrix.
- **Data Frame**. It is devoted to organize and analyze data and it is a generalization of the Matrix. In our example, **X** is a data frame.
- **List**. It is an object that can include Data Frames, Matrices or other lists.

```{r}
Y <- as.matrix(X[ ,1:4])
```

To handle data you can use the following code:

```{r}
X[10, 2]       # selection of one element in the Data Frame (or matrix)
X[5:20, 1:3]   # selection of an interval
X[5:20, ]      # the empty space select all the columns or rows
X$Sepal.Length # the symbol $ is used to select a column in the data frame
```
## 2.1. Plots in R

```{r}
boxplot(X$Sepal.Length, main = "Box Plot of the Sepal Length of the IRIS Flowers", col = "blue", horizontal = T)
```
The elements of the box-plot are reported below:

- **Q1**. It is the *First Quartile*. It leaves 25% of units on the left and 75% of units on the right. *Left side of the box*
- **Me**. It is the *Median=Q2*. It leaves 50% of units on left and right. *Bold Line in the middle of the box*
- **Q3**. It is the *Third Quartile*. It leaves 75% of the units on the left and 25% of the units on the right. *Right side of the box*
- In case of **no outliers**, the whiskers are defined as:
  - **Xmin** is the left whiskers
  - **Xmax** is the right whiskers
- In case of **outliers**, the whiskers are defined as:
  - **Linf** = Q1 - 1.5 (Q3-Q1): Lower Limit
  - **Lsup** = Q1 + 1.5 (Q3-Q1): Upper Limit
  
```{r}
# just a boxplot
boxplot(X[ ,1:4])
# boxplot with a title and colors
boxplot(X[ ,1:4], main = "Box Plot of all quantitative variables of IRIS data", col = terrain.colors(4))
```
  
```{r}
boxplot(X$Sepal.Width ~ X$Species, main = "Box Plot of Sepal Width considering the 3 types of flowers", xlab = "Type of IRIS Flowers", ylab = "Sepal Width", col = terrain.colors(4))
```

The *tilde symbol* is obtained by:

- these doesn't work [*]:
  - MAC: option + 5
  - WIN: ALT + 125/6
- these works [*]:
  - MAC: shift + button before no.1
  - WIN: shift + button before no.1

## [ 2.1. BONUS ]

The bold line is the **Median**, that is the value of the ordered distribution that leaves the same number of units above and below (or on left and right)

- **Q1** is the first quartile. Q1 leaves 25% of unirs on left and 75% on right.
- **Q3** is the third quartile. Q3 leaves 75% of units on left and 25% on right.
- Wishers, **without outliers** are, the min and max of distribution
- Wishers, **with outliers** are, Lmin = Q1-1.5*(Q3-Q1); Lsup = Q3+1.5*(Q3-Q1);

```{r}
boxplot(X$Sepal.Length, main = "Box-Plot of the Sepal Lenght", col = "green", horizontal = F)
boxplot(X[ ,1:4], main = "Box-Plot with all the Variables", col = "blue", horizontal = F)
boxplot(X$Sepal.Width ~ X$Species, main = "Box-Plot about Sepal Width with different type of IRIS Flowers")
```

## 2.2. Bar Plot

Bar Plot can be used for **Qualitative Data** and for **Categorized Quantitative Data**. The first step to create a Bar Plot is to generate a *Table of Frequency*.

```{r}
T <- table(X$Species)
T
```

```{r}
barplot(T, main = "Bar Plot of Type of flowers", xlab = "Type of flowers", ylab = "Absolute Frequency", col = terrain.colors(4))
```

## 2.3. Pie Chart

It is based on the frequency table.

```{r}
pie(T, main = "Pie Chart", col = terrain.colors(4))
```

## 2.4. Histogram Chart

Histogram is a plot used only for **Quantitative Data**, it is based on a frequency tables in classes. The *R* function is called *hist* and the input is a simple distribution of a quantitative variable.

```{r}
hist(X$Sepal.Length)
```

```{r}
hist(X$Sepal.Width, main = "Histogram of Sepal Width", xlab = "Classes", ylab = "Absolute Frequency", col = "lightgreen", border = "blue")
```

## [ 2.4. BONUS ]

he histogram can be used only for **quantitative variables**. 

```{r}
hist(X$Sepal.Width, main = "Histogram of the Sepal Width", xlab = "Classes",
     ylab = "Absolute Frequency", col = "green", border = "red", breaks = 10)

```

In case of equally spaced (same size) classes we can report on the *Y* axis the Absolute Frequency or relative frequency. In case of classes with different sizes we have to report on *Y* axis the *density of frequency*. The formula is the following: $d_i = n_i/h_i$, where $n_i$ is the absolute frequency and $h_i$ is the size of the class.

# 3. Correlation Analysis

## 3.1. Correlation Plot

```{r}
plot(X$Sepal.Length, X$Sepal.Width, main = "Correlation Plot", xlab = "Sepal Length", ylab = "Sepal Width")
```

## [ 3.1. BONUS ]

```{r}
plot(X$Petal.Length, X$Petal.Width, main = "Correlation Plot",
     xlab = "Petal Lenght", ylab = "Petal Width", col = "blue",
     pch = 1)
```

Plots with IRIS

```{r}
plot(X$Sepal.Length, X$Sepal.Width, main = "(1-2) Plot with IRIS", 
     xlab = "Sepal Lenght", ylab = "Sepal Width", col = "blue")
plot(X$Petal.Length, X$Petal.Width, main = "(2-2) Plot with IRIS", 
     xlab = "Petal Lenght", ylab = "Petal Width", col = "red")
```

## 3.2. Pair Plot

```{r}
pairs(X[ ,1:4])
```

The plots below the main diagonal are the same of the plot above the main diagonal. The reason is because the plot and the correlation index are symmetric.

```{r}
r <- cor(X[ ,1:2])
r <- round(r, 3)
r
cor(X$Sepal.Length, X$Sepal.Width)

```

The range of correlation index is: *-1 <= r <= 1*
The interpretation of the *Correlation Index* called **r** is following:

- 0.00 < |r| <= 0.25 *Low Correlation*
- 0.25 < |r| <= 0.50 *Medium-Low Correlation*
- 0.50 < |r| <= 0.75 *Medium-High Correlation*
- 0.75 < |r| <= 1.00 *High Correlation*
- 0 *No Correlation*
- 1 *Perfect Correlation*

The correlation between *Sepal Length* and *Sepal Width* is -0.118 and it is a low negative correlation.

# 4. Plots with GGPLOT Package

```{r}
install.packages("ggplot2")
library(ggplot2)
```

GGPLOTS has 3 main arguments:

- The first argument is the data: *ggplot(data = X)*. It creates an empty frame.
- The second argument is the geometry (type of plot): *geom_*. It adds a layer with the type of plot we want to show.
- The third argument is the aesthetic, to select the variables and the properties: *mapping = aes()*

```{r}
# GGPLOT (example no 1)
ggplot(data = X[ ,1:2])
# GGPLOT (example no 2.1)
ggplot(data = X[ ,1:2]) +
  geom_point(mapping = aes(X$Sepal.Length, X$Sepal.Width))
# GGPLOT (example no 2.2)
ggplot(data = X[ ,1:2]) +
  geom_point(mapping = aes(Sepal.Length, Sepal.Width))
# GGPLOT (example no 2.2)
ggplot(data = X) +
  geom_point(mapping = aes(Sepal.Length, Sepal.Width))
# GGPLOT (example no 3)
ggplot(data = X) +
  geom_point(mapping = aes(Sepal.Length, Sepal.Width)) +
  ggtitle("Scatter Plot") + xlab("Sepal Length") + ylab("Sepal Width")
```

## 4.1. Correlation Plot (Scatter Plot) with colors

```{r}
ggplot(data = X) +
  geom_point(mapping = aes(Sepal.Length, Sepal.Width, color = Species))
```

## [ 4.1. BONUS ]

**STANDARD TEMPLATE IS:**
  ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))

```{r}
# First Example
ggplot(data = X) + 
  geom_point(mapping = aes(Petal.Length, Petal.Width, color = Species)) +
  ggtitle("Petal Lenght and Width") +
  xlab("Petal Lenght") + ylab("Petal Width")
# Second Example
ggplot(data = X, mapping = aes(Petal.Width, Petal.Length)) + 
  geom_point(mapping = aes(color = Species)) +
  ggtitle("Petal Width and Lenght") + 
  xlab("Petal Width") + ylab("Petal Lenght")
```

## 4.2. Box Plot

```{r}
ggplot(data = X) +
  geom_boxplot(mapping = aes(Sepal.Width), color = "blue", outlier.colour = "red", outlier.shape = 8, outlier.size = 3) +
  ggtitle("Box Plot for Sepal Lenght")
```

Box Plot taking into account the 3 types of flowers

```{r}
ggplot(data = X) +
  geom_boxplot(mapping = aes(Species, Sepal.Width), outlier.color = "red", outlier.shape = 8)
```

GGPLOT function as object

```{r}
p <- ggplot(data = X) +
  geom_boxplot(mapping = aes(Species, Sepal.Width, fill = Species))
p
p + theme(legend.position = "bottom")
```

## 4.3. Bar Plot

```{r}
ggplot(data = X) + 
  geom_bar(mapping = aes(Species)) + 
  ggtitle("Bar Plot with GGPLOT") + 
  ylab("Absolute Frequency")
```

# 5. Use the mpg data (mpg Fuel economy data from 1999 to 2008 for 38 popular model of cars)

A data frame with 234 rows and 11 variables:

- *manufacturer* brand name
- *model* model name
- *displ* engine displacement, in litres (power of the engine)
- *year* year of manufacture
- *cyl* number of cylinders
- *trans* type of transmission
- *drv* the type of drive train, where f = front-wheel drive, r = rear wheel drive, 4 = 4wd
- *cty* city miles per gallon (km per liter in town)
- *hwy* highway miles per gallon (km per liter in highway)
- *fl* fuel type
- *class* "type" of car

```{r}
Y <- mpg
```

```{r}
summary(Y)
head(Y)
```

## 5.1. Bar Chart

```{r}
table(Y$cyl)
```

```{r}
# first example: factor(cyl) as a color ( vertical bar chart )
ggplot(data = Y) +
  geom_bar(mapping = aes(cyl, fill = factor(cyl)))
# second example: class as a color ( vertical bar chart )
ggplot(data = Y) +
  geom_bar(mapping = aes(cyl, fill = class))
# third example: class instead cyl ( vertical bar chart )
ggplot(data = Y) +
  geom_bar(mapping = aes(cyl, fill = class))
# fourth example: class instead cyl ( horizontal bar chart )
ggplot(data = Y) +
  geom_bar(mapping = aes(cyl, fill = class)) + coord_flip()
# fifth example: class instead cyl ( horizontal bar chart & legend at the bottom )
ggplot(data = Y) +
  geom_bar(mapping = aes(cyl, fill = class)) + coord_flip() + theme(legend.position = "bottom")
```

## 5.2. Histogram

```{r}
# example no 1.1
ggplot(data = Y) +
  geom_histogram(mapping = aes(cty))
# example no 1.2
ggplot(data = Y) +
  geom_histogram(mapping = aes(cty, colour = class))
# example no 1.3
ggplot(data = Y) +
  geom_histogram(mapping = aes(cty, fill = class))
# example no 1.4
ggplot(data = Y) +
  geom_histogram(mapping = aes(cty, fill = "red"))
# example no 1.5
ggplot(data = Y) +
  geom_histogram(mapping = aes(cty, fill = factor(cty)))
# example 2
ggplot(data = Y) +
  geom_histogram(mapping = aes(hwy))
```

## 5.3. Facet Wrap with 1 grup variable [*]

With Facet Wrap layer (option) we can create sub-plots based on a categorical variable.

```{r}
ggplot(data = Y) +
  geom_point(mapping = aes(displ, hwy)) +
  facet_wrap(~drv)
```

## 5.4. Facet Wrap with 2 grup variables [*]

```{r}
ggplot(data = Y) +
  geom_point(mapping = aes(displ, hwy)) +
  facet_wrap(drv ~ class)
```

## 5.5. Smooting Plot [*]

```{r}
ggplot(data = Y) +
  geom_smooth(mapping = aes(displ, hwy))
```

### 5.5.1. Smooting Plot with "different type of line" [*]

```{r}
# First Example
ggplot(data = Y) +
  geom_smooth(mapping = aes(displ, hwy, linetype = class))
# Second Example
ggplot(data = Y) +
  geom_smooth(mapping = aes(displ, hwy, linetype = drv))
```

### 5.5.2. Smooting Plot with "Facet Wrap" [*]

```{r}
ggplot(data = Y) +
  geom_smooth(mapping = aes(displ, hwy)) +
  facet_wrap(~ drv)
```

### 5.5.3. Smooting Plot with "color" [*]

```{r}
ggplot(data = Y) +
  geom_smooth(mapping = aes(displ, hwy, color = drv))
```

### 5.5.4. Smooting Plot with "group" [*]

```{r}
ggplot(data = Y) +
  geom_smooth(mapping = aes(displ, hwy, group = drv))
```

### 5.5.5. Smooting Plot combining different layers [*]

```{r}
ggplot(data = Y) +
  geom_point(mapping = aes(displ, hwy, color = drv)) +
  geom_smooth(mapping = aes(displ, hwy, color = drv))
```

# 6. Regression Model [*]

In regression model we need to define the *dependent* and *independent* variables. In our case the model is define as follow:

- *Y(Dependent/Outcome Variable)* = **hwy**. The variable defines the number of miles (km) per Gallon (liter) on the highway.
- *X(Independent/Input Variable)* = **displ**. The variable defines the power of the engine (horse power).

In the first place we need to create a scatter plot (correlation plot).

## 6.1. Regression Model: Plot [*]

```{r}
ggplot(data = Y) +
  geom_point(mapping = aes(displ, hwy)) +
  geom_smooth(method = lm, mapping = aes(displ, hwy))
```

## 6.2. Regression Model: Different Plot per each group [*]

```{r}
ggplot(data = Y) +
  geom_point(mapping = aes(displ, hwy, color  = drv)) +
  geom_smooth(method = lm, mapping = aes(displ, hwy, color = drv))
```

## 6.3. Regression Model: Parameters Estimation [*]

```{r}
res.reg <- lm(hwy ~ displ, data = Y)
summary(res.reg)
```
The regression coefficients are defined as follow:

- $\beta_0$ is the intercept and is the value of *Y* when *X* is equal to zero
- $\beta_1$ is the regression coefficient and is the slope of the line. It is the value of *Y* when there is a variant of *X* equal to 1: $\Delta_x=1$

### 6.3.1. Regression Parameters

The results of the regression model showed that the *estimated* $\beta_0$ (the intercept) is equal to **35.6977** and the estimated $\beta_1$ (the regression coefficient/slope) is equal to **-3.3506**.

### 6.3.2. Godness of Fit

The quality of the model is measured by the godness of fix index $R^2$ that is for this case study equal to **0.585**. The $R^2$ is interpreted as follow:

- 0.00 < $R^2$ <= 0.25 Low Quality
- 0.25 < $R^2$ <= 0.50 Medium-Low Quality
- 0.50 < $R^2$ <= 0.75 Medium-High Quality
- 0.75 < $R^2$ < 1.00 High Quality
- $R^2$ = 0 Non connection between *Y* and *X*. The result will be on horizontal line
- $R^2$ = 1 Perfect connection between *Y* and *X*. The data points will be exactly on the regression line

In this case study we have a Medium-High Quality of the model.

### 6.3.3. Test on the estimated Regression Parameters

To test the regression parameters it is possible to use the *t-value* or the *p-value*, as reported below:

- Approach by using the *t-value*:
  - -2 < *t-value* < 2 we accept the null hypothesis (BAD). The relation between *Y* and *X* is **not statistically significant**.
  - *t-value* > 2 we reject the null hypothesis (GOOD). The relation between *Y* and *X* is **statistically significant**
  - *t-value* < -2 we reject the null hypothesis (GOOD). The relation between *Y* and *X* is **statistically significant**.
- Approach by using the *p-value*:
  - *p-value* > 0.05 (5%) we accept the null hypothesis (BAD). The relation between *Y* and *X* is **not statistically significant**.
  - *p-value* < 0.05 (5%) we reject the null hypothesis (GOOD). The relation between *Y* and *X* is **statistically significant**.

In this case study the estimated regression coefficient $\beta_1$ is **statistically significant**, since the *t-value* is **-18.15** (< 2) and the *p-value* is **2e-16** (< 5%).
It means that the *number of mile per gallon* (hwy) depends by the *power of the engine* (displ), so by increasing the *displ* of 1 unit, the *hwy* will decrease by **-3.5306**.

# 7. Principal Component Analysis (PCA) [ BONUS ]

The Principal Component Analysis has the following aims and characteristics:

- PCA is only for **Quantitative DATA**
- Data Reduction by creating a new set of Latent Variables in a number *q* < *p*, where *p* is the the numer of the manifest/original variables.
- Discover *Latent Traits*/*Latent Variables* in the data. 

```{r}
library(FactoMineR)
library(ggplot2)
library(factoextra)
```

For the PCA we will use the *PCA* function in the Package *FactoMineR*.

```{r}
Y <- mpg
```

## 7.1 PCA for mpg Data

```{r}
res.pca <- PCA(Y[,c(3,5,8,9)])
summary(res.pca)
```

## 7.2 PCA on mtcars

```{r}
Z <- mtcars
```

```{r}
res.pca1 <- PCA(Z)
summary(res.pca1)
```

### 7.2.1 Eigenvalues interpretation 

The *eigenvalues* measure the level of information retained by the PCA. They show the *explained variance* from the data and help us to select the number of *Latent Variables* (or Latent Traits, Principal Components, Dimensions). 
The rules to select the number of LVs are:
- Eigenvalues greater than 1. $\lambda > 1$.
- Cumulative percentage of explained variance > 0.7 (70%)

In our case study we select two components. Both components have eigenvalue greater than 1 and with and Cumulative percentage of explained variance equal to 84.172%.

```{r}
round(res.pca1$eig,3)
```

### 7.2.2 Variables Plot (Variables Dimension)

Below we can read the table with **correlations** between the Manifest Variables (MVs) and the Latent Variables (Dimensions). The correlations are also the **coordinates** of the manifest variables on the variables plot.

For the interpretation:

- Higher is the correlation(bigger is the coordinate), higher is the importance of the manifest variable for the latent variable(Dimension).
- The **sign of correlation** give information about the position of the manifest variable:
  + On the *first dimension*: Positive sign, the MV is on the right side; Negative sign, the MV is on the left side
  + On the *second dimension*: Positive sign, the MV is on the upper side; Negative sign, the MV is on the lower side
- We can give a meaning to the two Latent Variables (Dimensions) based on the correlation and the sign.

In our case study, the LVs (dimensions) are so defined:

- $LV_1$: *Right side* (cyl, disp, hp, wt); *Left side* (mpg, drat, vs)
- $LV_2$. *Upper side* (am, gear, carb); *Lower side* (qsec)

```{r}
round(res.pca1$var$coord[,1:2],3)
```

it is possible to evaluate the correlations between the manifest variables by using the angle between the vectors. For instance, the variables *hp*, *cyl*, *disp* and *wt* are all positively correlated since all the angles are less then 90°.

```{r}
plot.PCA(res.pca1, axes = c(1,2), choix = "var")
```

The quality of the projected manifest variables is given by the **Cosine squared**. 

Below you can find the interpretation intervals:

- 0.00 < $Cos^2$ <= 0.25: Low Quality
- 0.25 < $Cos^2$ <= 0.50: Medium-Low Quality
- 0.50 < $Cos^2$ <= 0.75: Medium-High Quality
- 0.75 < $Cos^2$ <= 1.00: High Quality

```{r}
round(res.pca1$var$cos2[,1:2],3)
```

### 7.2.3 Units Plot

In the units plot we can evaluate the clusters of units. The clusters define group of units that are similar on the basis of the Latent Variables estimated.

```{r}
plot.PCA(res.pca1, axes = c(1,2), choix = "ind")
```
## 7.3 PCA with Factoextra Package

```{r}
library(factoextra)
```

### 7.3.1 Variables Plot

```{r}
fviz_pca_var(res.pca1)
```

### 7.3.2 Units Plot

```{r}
fviz_pca_ind(res.pca1)
```

### 7.3.3 BiPlot

Biplot is a plot where both units and variables are represented.

```{r}
fviz_pca_biplot(res.pca1)
```

## 7.3.4 Graphical representation of the **Eigenvalues**

```{r}
fviz_screeplot(res.pca1)
```

## 7.3.5 Graphical representation of the **Contributions** of the manifest variables

```{r}
fviz_pca_contrib(res.pca1, choice = "var")
```

